{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "admissions_data = \"\"\"34.62365962451697,78.0246928153624,030.28671076822607,43.89499752400101,\n",
    "0\n",
    "35.84740876993872,\n",
    "72.90219802708364,\n",
    "0\n",
    "60.18259938620976,\n",
    "86.30855209546826,\n",
    "1\n",
    "79.0327360507101,\n",
    "75.3443764369103,\n",
    "1\n",
    "45.08327747668339,\n",
    "56.3163717815305,\n",
    "0\n",
    "61.10666453684766,\n",
    "96.51142588489624,\n",
    "1\n",
    "75.02474556738889,\n",
    "46.55401354116538,\n",
    "1\n",
    "76.09878670226257,\n",
    "87.42056971926803,\n",
    "1\n",
    "84.43281996120035,\n",
    "43.53339331072109,\n",
    "1\n",
    "95.86155507093572,\n",
    "38.22527805795094,\n",
    "0\n",
    "75.01365838958247,\n",
    "30.60326323428011,\n",
    "0\n",
    "82.30705337399482,\n",
    "76.48196330235604,\n",
    "1\n",
    "69.36458875970939,\n",
    "97.71869196188608,\n",
    "1\n",
    "39.53833914367223,\n",
    "76.03681085115882,\n",
    "0\n",
    "53.9710521485623,\n",
    "89.20735013750205,\n",
    "1\n",
    "69.07014406283025,\n",
    "52.74046973016765,\n",
    "1\n",
    "67.94685547711617,\n",
    "46.67857410673128,\n",
    "0\n",
    "70.66150955499435,\n",
    "92.92713789364831,\n",
    "1\n",
    "76.97878372747498,\n",
    "47.57596364975532,\n",
    "1\n",
    "67.37202754570876,\n",
    "42.83843832029179,\n",
    "0\n",
    "89.67677575072079,\n",
    "65.79936592745237,\n",
    "1\n",
    "50.534788289883,\n",
    "48.85581152764205,\n",
    "0\n",
    "34.21206097786789,\n",
    "44.20952859866288,\n",
    "0\n",
    "77.9240914545704,\n",
    "68.9723599933059,\n",
    "1\n",
    "62.27101367004632,\n",
    "69.95445795447587,\n",
    "1\n",
    "80.1901807509566,\n",
    "44.82162893218353,\n",
    "1\n",
    "93.114388797442,\n",
    "38.80067033713209,\n",
    "0\n",
    "61.83020602312595,\n",
    "50.25610789244621,\n",
    "0\n",
    "38.78580379679423,\n",
    "64.99568095539578,\n",
    "0\n",
    "61.379289447425,\n",
    "72.80788731317097,\n",
    "1\n",
    "85.40451939411645,\n",
    "57.05198397627122,\n",
    "1\n",
    "52.10797973193984,\n",
    "63.12762376881715,\n",
    "0\n",
    "52.04540476831827,\n",
    "69.43286012045222,\n",
    "1\n",
    "40.23689373545111,\n",
    "71.16774802184875,\n",
    "0\n",
    "54.63510555424817,\n",
    "52.21388588061123,\n",
    "0\n",
    "33.91550010906887,\n",
    "98.86943574220611,\n",
    "0\n",
    "64.17698887494485,\n",
    "80.90806058670817,\n",
    "1\n",
    "74.78925295941542,\n",
    "41.57341522824434,\n",
    "0\n",
    "34.1836400264419,\n",
    "75.2377203360134,\n",
    "0\n",
    "83.90239366249155,\n",
    "56.30804621605327,\n",
    "1\n",
    "51.54772026906181,\n",
    "46.85629026349976,\n",
    "0\n",
    "94.44336776917852,\n",
    "65.56892160559052,\n",
    "1\n",
    "82.36875375713919,\n",
    "40.61825515970618,\n",
    "0\n",
    "51.04775177128865,\n",
    "45.82270145776001,\n",
    "0\n",
    "62.22267576120188,\n",
    "52.06099194836679,\n",
    "0\n",
    "77.19303492601364,\n",
    "70.45820000180959,\n",
    "1\n",
    "97.77159928000232,\n",
    "86.7278223300282,\n",
    "1\n",
    "62.07306379667647,\n",
    "96.76882412413983,\n",
    "1\n",
    "91.56497449807442,\n",
    "88.69629254546599,\n",
    "1\n",
    "79.94481794066932,\n",
    "74.16311935043758,\n",
    "1\n",
    "99.2725269292572,\n",
    "60.99903099844988,\n",
    "1\n",
    "90.54671411399852,\n",
    "43.39060180650027,\n",
    "1\n",
    "34.52451385320009,\n",
    "60.39634245837173,\n",
    "0\n",
    "50.2864961189907,\n",
    "49.80453881323059,\n",
    "0\n",
    "49.58667721632031,\n",
    "59.80895099453265,\n",
    "0\n",
    "97.64563396007767,\n",
    "68.86157272420604,\n",
    "1\n",
    "32.57720016809309,\n",
    "95.59854761387875,\n",
    "0\n",
    "74.24869136721598,\n",
    "69.82457122657193,\n",
    "1\n",
    "71.79646205863379,\n",
    "78.45356224515052,\n",
    "1\n",
    "75.3956114656803,\n",
    "85.75993667331619,\n",
    "1\n",
    "35.28611281526193,\n",
    "47.02051394723416,\n",
    "0\n",
    "56.25381749711624,\n",
    "39.26147251058019,\n",
    "0\n",
    "30.05882244669796,\n",
    "49.59297386723685,\n",
    "0\n",
    "44.66826172480893,\n",
    "66.45008614558913,\n",
    "0\n",
    "66.56089447242954,\n",
    "41.09209807936973,\n",
    "0\n",
    "40.45755098375164,\n",
    "97.53518548909936,\n",
    "1\n",
    "49.07256321908844,\n",
    "51.88321182073966,\n",
    "0\n",
    "80.27957401466998,\n",
    "92.11606081344084,\n",
    "1\n",
    "66.74671856944039,\n",
    "60.99139402740988,\n",
    "1\n",
    "32.72283304060323,\n",
    "43.30717306430063,\n",
    "0\n",
    "64.0393204150601,\n",
    "78.03168802018232,\n",
    "1\n",
    "72.34649422579923,\n",
    "96.22759296761404,\n",
    "1\n",
    "60.45788573918959,\n",
    "73.09499809758037,\n",
    "1\n",
    "58.84095621726802,\n",
    "75.85844831279042,\n",
    "1\n",
    "99.82785779692128,\n",
    "72.36925193383885,\n",
    "1\n",
    "47.26426910848174,\n",
    "88.47586499559782,\n",
    "1\n",
    "50.45815980285988,\n",
    "75.80985952982456,\n",
    "1\n",
    "60.45555629271532,\n",
    "42.50840943572217,\n",
    "0\n",
    "82.22666157785568,\n",
    "42.71987853716458,\n",
    "0\n",
    "88.9138964166533,\n",
    "69.80378889835472,\n",
    "1\n",
    "94.83450672430196,\n",
    "45.69430680250754,\n",
    "1\n",
    "67.31925746917527,\n",
    "66.58935317747915,\n",
    "1\n",
    "57.23870631569862,\n",
    "59.51428198012956,\n",
    "1\n",
    "80.36675600171273,\n",
    "90.96014789746954,\n",
    "1\n",
    "68.46852178591112,\n",
    "85.59430710452014,\n",
    "1\n",
    "42.0754545384731,\n",
    "78.84478600148043,\n",
    "0\n",
    "75.47770200533905,\n",
    "90.42453899753964,\n",
    "1\n",
    "78.63542434898018,\n",
    "96.64742716885644,\n",
    "1\n",
    "52.34800398794107,\n",
    "60.76950525602592,\n",
    "0\n",
    "94.09433112516793,\n",
    "77.15910509073893,\n",
    "1\n",
    "90.44855097096364,\n",
    "87.50879176484702,\n",
    "1\n",
    "55.48216114069585,\n",
    "35.57070347228866,\n",
    "0\n",
    "74.49269241843041,\n",
    "84.84513684930135,\n",
    "1\n",
    "89.84580670720979,\n",
    "45.35828361091658,\n",
    "1\n",
    "83.48916274498238,\n",
    "48.38028579728175,\n",
    "1\n",
    "42.2617008099817,\n",
    "87.10385094025457,\n",
    "1\n",
    "99.31500880510394,\n",
    "68.77540947206617,\n",
    "1\n",
    "55.34001756003703,\n",
    "64.9319380069486,\n",
    "1\n",
    "74.77589300092767,\n",
    "89.52981289513276,\n",
    "1\"\"\"\n",
    "\n",
    "with open('./data/admissions.csv', 'w') as f:\n",
    "    f.write(admissions_data)\n",
    "\n",
    "X_features = ['Exam 1 score', 'Exam 2 score'\n",
    "]\n",
    "y_name = ['Admitted'\n",
    "]\n",
    "data = pd.read_csv(\"./data/admissions.csv\", header=None, names=X_features + y_name)\n",
    "\n",
    "X = data[X_features\n",
    "].values\n",
    "y = data[y_name\n",
    "].values\n",
    "m = y.size  # number of training examples\n",
    "\n",
    "pos = y == 1\n",
    "neg = y == 0\n",
    "plt.scatter(X[pos[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    0\n",
    "], X[pos[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    1\n",
    "], marker='o', c='k', label='Admitted')\n",
    "plt.scatter(X[neg[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    0\n",
    "], X[neg[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    1\n",
    "], marker='o', c='y', label='Not Admitted')\n",
    "plt.xlabel('Bidimensional data')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(X, y, w, b):\n",
    "    m = y.size\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    cost = - (1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "def compute_gradient(X, y, w, b):\n",
    "    m = X.shape\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    error = h - y\n",
    "    dj_dw = (1 / m) * np.dot(X.T, error)\n",
    "    dj_db = (1 / m) * np.sum(error)\n",
    "    return dj_db, dj_dw\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters):\n",
    "    w = w_in.copy()\n",
    "    b = b_in\n",
    "    for i in range(num_iters):\n",
    "        dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost(X, y, w, b)\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "    return w, b\n",
    "\n",
    "def predict(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    return h >= 0.5\n",
    "\n",
    "\n",
    "w_init = np.zeros((X.shape[\n",
    "    1\n",
    "],\n",
    "1))\n",
    "b_init = 0.0\n",
    "alpha = 0.001  # Taxa de aprendizado\n",
    "num_iters = 10000\n",
    "\n",
    "y = y.reshape(-1,\n",
    "1)\n",
    "cost_history = []\n",
    "w = w_init.copy()\n",
    "b = b_init\n",
    "\n",
    "print(f\"\\nParâmetros iniciais:\")\n",
    "print(f\"  w: {w.flatten()}\")\n",
    "print(f\"  b: {b}\")\n",
    "print(f\"  Taxa de aprendizado (α): {alpha}\")\n",
    "print(f\"  Número de iterações: {num_iters}\")\n",
    "\n",
    "\n",
    "for i in range(num_iters):\n",
    "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "    w -= alpha * dj_dw\n",
    "    b -= alpha * dj_db\n",
    "    \n",
    "    # armazenar custo a cada iteração\n",
    "    cost = compute_cost(X, y, w, b)\n",
    "    cost_history.append(cost)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Iteração {i:5d}: Custo = {cost:.6f}\")\n",
    "\n",
    "w_final = w\n",
    "b_final = b\n",
    "\n",
    "print(f\"\\nResultado:\")\n",
    "print(f\"  w: {w_final.flatten()}\")\n",
    "print(f\"  b: {b_final:.6f}\")\n",
    "print(f\"  Custo final: {cost_history[-1]:.6f}\")\n",
    "\n",
    "y_pred = predict(X, w_final, b_final)\n",
    "y_pred_proba = sigmoid(np.dot(X, w_final) + b_final)\n",
    "\n",
    "accuracy = np.mean(y_pred == y) * 100\n",
    "print(f\"\\nAcurácia do modelo: {accuracy:.2f}%\")\n",
    "\n",
    "print(f\"\\nExemplos de previsões (primeiros 10 casos):\")\n",
    "print(f\"{'Exam 1':>10} | {'Exam 2':>10} | {'Real':>6} | {'Predito':>8} | {'Prob.':>8}\")\n",
    "for i in range(10):\n",
    "    print(f\"{X[i, 0]:10.2f} | {X[i, 1]:10.2f} | {int(y[i, 0]):6d} | {int(y_pred[i, 0]):8d} | {y_pred_proba[i, 0]:8.4f}\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,\n",
    "12))\n",
    "\n",
    "# Custo\n",
    "ax1 = plt.subplot(2,\n",
    "3,\n",
    "1)\n",
    "ax1.plot(cost_history, linewidth=2, color='blue')\n",
    "ax1.set_xlabel('Iteração', fontsize=11)\n",
    "ax1.set_ylabel('Custo J(w, b)', fontsize=11)\n",
    "ax1.set_title('Evolução da Função de Custo (Escala Linear)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.text(0.98,\n",
    "0.98, f'Custo Final: {cost_history[\n",
    "        -1\n",
    "    ]:.6f\n",
    "}', \n",
    "         transform=ax1.transAxes, ha='right', va='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "         fontsize=10)\n",
    "\n",
    "# escala log\n",
    "ax2 = plt.subplot(2,\n",
    "3,\n",
    "2)\n",
    "ax2.plot(cost_history, linewidth=2, color='green')\n",
    "ax2.set_xlabel('Iteração', fontsize=11)\n",
    "ax2.set_ylabel('Custo J(w, b)', fontsize=11)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Evolução da Função de Custo (Escala Log)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Fronteira\n",
    "ax3 = plt.subplot(2,\n",
    "3,\n",
    "3)\n",
    "pos = y == 1\n",
    "neg = y == 0\n",
    "ax3.scatter(X[pos[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    0\n",
    "], X[pos[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    1\n",
    "], marker='o', c='green', \n",
    "            s=80, edgecolors='black', linewidth=1.5, label='Admitido (y=1)', alpha=0.7)\n",
    "ax3.scatter(X[neg[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    0\n",
    "], X[neg[\n",
    "        : ,\n",
    "        0\n",
    "    ],\n",
    "    1\n",
    "], marker='x', c='red', \n",
    "            s=80, linewidth=2, label='Não Admitido (y=0)', alpha=0.7)\n",
    "x1_min, x1_max = X[\n",
    "    : ,\n",
    "    0\n",
    "].min() - 5, X[\n",
    "    : ,\n",
    "    0\n",
    "].max() + 5\n",
    "x2_min, x2_max = X[\n",
    "    : ,\n",
    "    1\n",
    "].min() - 5, X[\n",
    "    : ,\n",
    "    1\n",
    "].max() + 5\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max,\n",
    "200),\n",
    "                       np.linspace(x2_min, x2_max,\n",
    "200))\n",
    "X_grid = np.c_[xx1.ravel(), xx2.ravel()\n",
    "]\n",
    "Z = sigmoid(np.dot(X_grid, w_final) + b_final)\n",
    "Z = Z.reshape(xx1.shape)\n",
    "\n",
    "contours = ax3.contour(xx1, xx2, Z, levels=[\n",
    "    0.5\n",
    "], colors='blue', linewidths=3)\n",
    "ax3.clabel(contours, inline=True, fontsize=10, fmt='Decisão: %.1f')\n",
    "ax3.contourf(xx1, xx2, Z, levels=20, cmap='RdYlGn', alpha=0.3)\n",
    "ax3.set_xlabel('Nota Exame 1', fontsize=11)\n",
    "ax3.set_ylabel('Nota Exame 2', fontsize=11)\n",
    "ax3.set_title('Dados com Fronteira de Decisão', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Função Sigmoid\n",
    "ax4 = plt.subplot(2,\n",
    "3,\n",
    "4)\n",
    "z_range = np.linspace(-10,\n",
    "10,\n",
    "100)\n",
    "sigmoid_vals = sigmoid(z_range)\n",
    "ax4.plot(z_range, sigmoid_vals, linewidth=3, color='purple')\n",
    "ax4.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Limite de Decisão (0.5)')\n",
    "ax4.axvline(x=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax4.set_xlabel('z = w·x + b', fontsize=11)\n",
    "ax4.set_ylabel('σ(z)', fontsize=11)\n",
    "ax4.set_title('Função Sigmoid', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.text(0.02,\n",
    "0.98, 'σ(z) = 1 / (1 + e⁻ᶻ)', \n",
    "         transform=ax4.transAxes, ha='left', va='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "         fontsize=10, style='italic')\n",
    "\n",
    "# Distribuição de Probabilidades\n",
    "ax5 = plt.subplot(2,\n",
    "3,\n",
    "5)\n",
    "probs_class_0 = y_pred_proba[y.flatten() == 0\n",
    "]\n",
    "probs_class_1 = y_pred_proba[y.flatten() == 1\n",
    "]\n",
    "ax5.hist(probs_class_0, bins=20, alpha=0.6, label='Classe 0 (Não Admitido)', \n",
    "         color='red', edgecolor='black')\n",
    "ax5.hist(probs_class_1, bins=20, alpha=0.6, label='Classe 1 (Admitido)', \n",
    "         color='green', edgecolor='black')\n",
    "ax5.axvline(x=0.5, color='blue', linestyle='--', linewidth=2, label='Threshold = 0.5')\n",
    "ax5.set_xlabel('Probabilidade Predita', fontsize=11)\n",
    "ax5.set_ylabel('Frequência', fontsize=11)\n",
    "ax5.set_title('Distribuição de Probabilidades por Classe', fontsize=12, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Matriz de Confusão Visual\n",
    "ax6 = plt.subplot(2,\n",
    "3,\n",
    "6)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "im = ax6.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax6.set_title('Matriz de Confusão', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax6)\n",
    "tick_marks = np.arange(2)\n",
    "ax6.set_xticks(tick_marks)\n",
    "ax6.set_yticks(tick_marks)\n",
    "ax6.set_xticklabels(['Não Admitido', 'Admitido'\n",
    "])\n",
    "ax6.set_yticklabels(['Não Admitido', 'Admitido'\n",
    "])\n",
    "ax6.set_xlabel('Predito', fontsize=11)\n",
    "ax6.set_ylabel('Real', fontsize=11)\n",
    "\n",
    "thresh = cm.max() / 2\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax6.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=16, fontweight='bold')\n",
    "plt.suptitle('ANÁLISE COMPLETA DA REGRESSÃO LOGÍSTICA', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"  • Acurácia: {accuracy:.2f}%\")\n",
    "print(f\"  • Custo inicial: {cost_history[0]:.6f}\")\n",
    "print(f\"  • Custo final: {cost_history[-1]:.6f}\")\n",
    "print(f\"  • Redução do custo: {((cost_history[0] - cost_history[-1]) / cost_history[0] * 100):.2f}%\")\n",
    "print(f\"\\n  • Matriz:\")\n",
    "print(f\"      VP: {cm[1, 1]} | FP: {cm[0, 1]}\")\n",
    "print(f\"      FN: {cm[1, 0]} | VN: {cm[0, 0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
